I am creating a pytorch script to train a lstm neural network, the neural network does ternary classification.

The dataset is initialized with a root_dir, within this root_dir, there are three subdirectories: CP, NCP and Normal. 

Each of this subdirectories represents an specific label, 'NCP' contains scans with Common Pneumonia, 'CP' contains scans with COVID-19 and 'Normal' contain scans that are within normal limits and do not show any pathology. 

Each subdirectory contains subfolders that correspond to the patient_id, inside each patient_id folder there are scan folders where each scan folder has a number of jpg files that corresponds to slices in a scan.

For example 'NCP' scans are stored like 'root_dir/NCP/9999/9999/9999.jpg', 'CP' are stored like 'root_dir/CP/9999/9999/9999.jpg' and 'root_dir/Normal/9999/9999/9999.jpg' are stored like 'root_dir/CP/9999/9999/9999.jpg'. 

I need your help to create a Dataset class that will make these files as proper input to a LSTM network I'm gonna train in Pytorch. 

The LSTM network input is a sequence of vectors that represents a scan. 

Each vector is an embedding representation of a slice of that scan.

To generate the embeddings representation use the flattened version of the features extracted from the CNN_Net CNN (after the convolutional layers and before the fully connected layers) as a 1D feature vector for further processing.

Also suggest and LSTM for me to train with the Dataset class you will create.

I will share with you CCCCIIDataset2D as a reference of the Dataset class I used to train the CNN_Net.

Use the same approach as CCCCIIDataset2D gettting central 30 slices.

trained CNN_Net will be available at models/cnn_multiclass_lung_disease_249741samples_epoch4_lr0.00050.pth


CNN_Net:
class CNN_Net(nn.Module):
    def __init__(self, num_classes, input_height, input_width, dropout_rate=0.5):
        super(CNN_Net, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(dropout_rate),  # Dropout after pooling
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(dropout_rate),  # Dropout after pooling
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(dropout_rate),  # Dropout after pooling
        )
        self.fc = nn.Linear(128 * (input_height // 8) * (input_width // 8), num_classes)
        
    def forward(self, x, return_embedding=False):
        if len(x.size()) != 4:
            raise ValueError(f"Expected 4D input (batch_size, channels, height, width), got {x.size()}")

        batch_size, channels, height, width = x.size()
        x = x.float()
        embedding = self.cnn(x)
        flattened = embedding.view(batch_size, -1)
        
        if return_embedding:
            return flattened  # Retorna apenas o embedding

        x = self.fc(flattened)
        return x

CCCCIIDataset2D:
import os
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
import os
import random

from utils.log_config import get_custom_logger

my_logger = get_custom_logger('ccccii_dataset')

class CCCCIIDataset2D(Dataset):
    def __init__(self, root_dir, transform=None, max_samples=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = {'CP': 0, 'NCP': 1, 'Normal': 2}
        self.num_classes = len(self.classes)  # Number of classes
        self.max_samples = max_samples
        
        my_logger.info(f"[cccii_dataset] Dataset initialized with root_dir: {self.root_dir}")
        my_logger.info(f"[cccii_dataset] Transform: {self.transform}")
        my_logger.info(f"[cccii_dataset] Max samples: {self.max_samples}")
        my_logger.info(f"[cccii_dataset] Number of classes: {self.num_classes}")
        my_logger.info(f"[cccii_dataset] Labels : {self.classes}")
        
        self.data = self._gather_data()

    def _gather_data(self):
        data = []
        patient_list = []
        sample_counts = {class_idx: 0 for class_idx in self.classes.values()}  # Initialize counters per class

        my_logger.info(f"[cccii_dataset] Current working directory: {os.getcwd()}")
        my_logger.info(f"[cccii_dataset] Contents of root directory ({self.root_dir}): {os.listdir(self.root_dir)}")

        # Collect all patients across all classes
        for label, class_idx in self.classes.items():
            class_dir = os.path.join(self.root_dir, label)
            patients = os.listdir(class_dir)
            for patient_id in patients:
                patient_dir = os.path.join(class_dir, patient_id)
                for scan_folder in os.listdir(patient_dir):
                    scan_path = os.path.join(patient_dir, scan_folder)
                    slices = os.listdir(scan_path)
                    if len(slices) >= 30:
                        patient_list.append((scan_path, class_idx))  # Collect scan paths with class labels

        random.seed(42)  # Set the random seed for reproducibility
        random.shuffle(patient_list)  # Shuffle the patient list across all classes

        count = 0
        for scan_path, class_idx in patient_list:
            slices = sorted(os.listdir(scan_path))
            num_slices = len(slices)
            # Calculate start and end indices for central 30 slices
            start_idx = max(0, (num_slices - 30) // 2)
            end_idx = start_idx + 30
            end_idx = min(end_idx, num_slices)  # Ensure end_idx doesn't exceed total slices

            for slice_idx in range(start_idx, end_idx):
                data.append((scan_path, slice_idx, class_idx))
                sample_counts[class_idx] += 1
                count += 1
                if self.max_samples and count >= self.max_samples:
                    my_logger.info(f"[cccii_dataset] Total samples : {len(data)}")
                    my_logger.info(f"[cccii_dataset] Samples per class : {sample_counts}")
                    return data
            # Move to the next patient once one scan is processed

        my_logger.info(f"[cccii_dataset] Total samples : {len(data)}")
        my_logger.info(f"[cccii_dataset] Samples per class : {sample_counts}")
        return data

    def __len__(self):
        return len(self.data)

    def _load_scan(self, scan_path, slice_idx):
        slice_files = sorted(os.listdir(scan_path))
        slice_file = slice_files[slice_idx]
        slice_path = os.path.join(scan_path, slice_file)
        img = Image.open(slice_path).convert('L')  # Convert to grayscale
        img = img.resize((512, 512))  # Resize to 512x512
        img = np.array(img)
        img = img.astype(np.float32)
        np.seterr(invalid='raise')
        mean = np.mean(img)
        std = np.std(img)        
        if std > 0:
            img = (img - mean) / std  # Normalize intensities only if std is non-zero
        else:
            my_logger.info(f"[cccii_dataset]Image is zero std: {scan_path} - {slice_idx}")            
            img = img - mean  # If std is zero, simply subtract the mean        
        return img

    def _extract_patient_id(self, scan_path):
        # Split the path to get the directory corresponding to the patient
        patient_dir = os.path.dirname(scan_path)
        # Split again to get the name of the patient directory, which is the patient ID
        patient_id = os.path.basename(os.path.dirname(patient_dir))
        return patient_id

    def __getitem__(self, idx):
        scan_path, slice_idx, label = self.data[idx]
        img = self._load_scan(scan_path, slice_idx)
        
        patient_id = self._extract_patient_id(scan_path)

        if self.transform:
            img = self.transform(img)
        
        # Ensure the image is of shape (1, 512, 512) by adding a channel dimension
        img = torch.tensor(img).unsqueeze(0)  # Add the channel dimension
        
        # Return the image, patient ID, and the label
        return img, patient_id, torch.tensor(label).long()
